{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "121293a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Legal AI Project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.chains import MapReduceDocumentsChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "from utils import load_pdf_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6bc30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = \"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\"\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Global constants\n",
    "# ------------------------------------------------------\n",
    "VECTOR_DB_PATH = \"vector_db\"\n",
    "KNOWLEDGE_BASE_PATH = \"data/IT_Act_2000.pdf\"\n",
    "\n",
    "\n",
    "MAX_PAGES_TO_PROCESS = 25  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34d3efe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vectorstore():\n",
    "    from langchain_community.document_loaders import PyMuPDFLoader\n",
    "    \n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    \n",
    "    if os.path.exists(VECTOR_DB_PATH):\n",
    "        print(\"ðŸ“¦ Using cached vector store\")\n",
    "        return Chroma(persist_directory=VECTOR_DB_PATH, embedding_function=embeddings)\n",
    "    \n",
    "    print(\"ðŸ”¨ Building vector store (one-time setup)...\")\n",
    "    loader = PyMuPDFLoader(KNOWLEDGE_BASE_PATH)\n",
    "    documents = loader.load()\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=80)\n",
    "    kb_chunks = splitter.split_documents(documents)\n",
    "\n",
    "    vector_store = Chroma.from_documents(kb_chunks, embeddings, persist_directory=VECTOR_DB_PATH)\n",
    "    print(f\"âœ… Vector store ready with {len(kb_chunks)} chunks\")\n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "925d1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_vectorstore_info():\n",
    "    \"\"\"\n",
    "    Display Chroma vector DB stats: number of vectors, collections, and sample metadata.\n",
    "    \"\"\"\n",
    "    from chromadb import PersistentClient\n",
    "\n",
    "    # Path must match your persist_directory\n",
    "    client = PersistentClient(path=VECTOR_DB_PATH)\n",
    "\n",
    "    collections = client.list_collections()\n",
    "    print(f\"ðŸ§  Found {len(collections)} collections in Chroma DB:\\n\")\n",
    "\n",
    "    for c in collections:\n",
    "        print(f\"ðŸ“‚ Collection name: {c.name}\")\n",
    "        print(f\"   â†’ Metadata: {c.metadata}\")\n",
    "        print(f\"   â†’ Vector count: {c.count()}\\n\")\n",
    "\n",
    "    # Example: Inspect the 'legal_cases' or default collection\n",
    "    try:\n",
    "        coll = client.get_collection(\"langchain\")  # default if no name specified\n",
    "        print(f\"ðŸ” Inspecting default collection '{coll.name}':\")\n",
    "        print(f\"   â†’ Count: {coll.count()} vectors\")\n",
    "\n",
    "        sample = coll.get(limit=2, include=[\"documents\", \"metadatas\"])\n",
    "        print(\"ðŸª¶ Sample documents:\")\n",
    "        for doc, meta in zip(sample[\"documents\"], sample[\"metadatas\"]):\n",
    "            print(f\" - {meta} :: {doc[:120]}...\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Could not inspect default collection: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0dd9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = build_vectorstore()\n",
    "inspect_vectorstore_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3262fe44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vansh\\AppData\\Local\\Temp\\ipykernel_24616\\1108465763.py:9: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedder = SentenceTransformerEmbeddings(model_name=EMBED_MODEL)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Same embedding you use elsewhere (keep consistent!)\n",
    "EMBED_MODEL = \"all-MiniLM-L6-v2\"\n",
    "embedder = SentenceTransformerEmbeddings(model_name=EMBED_MODEL)\n",
    "\n",
    "# Regex to catch explicit IT Act mentions/sections\n",
    "IT_REGEX = re.compile(\n",
    "    r\"(Information\\s+Technology\\s+Act|IT\\s+Act|Sec(?:tion)?\\s*\\d+[A-Z]?\\s*of\\s+the\\s+IT\\s*Act|Section\\s*(66[A-Z]?|67[A-Z]?|72))\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def build_it_centroid(queries: List[str]) -> np.ndarray:\n",
    "    Q = embedder.embed_documents(queries)  # list -> list[vec]\n",
    "    return np.mean(np.array(Q), axis=0, keepdims=True)  # shape (1, d)\n",
    "\n",
    "def score_chunks_against_it(\n",
    "    chunks: List[str],\n",
    "    it_queries: List[str],\n",
    "    tau_chunk: float = 0.70,\n",
    "    tau_doc: float = 0.72,\n",
    "    regex_bonus: float = 0.05,\n",
    "    min_pos_chunks_for_doc: int = 2,\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      {\n",
    "        \"chunk_scores\": List[{\"idx\": i, \"sim\": float, \"regex_hit\": bool, \"final\": float}],\n",
    "        \"doc_score_max\": float,\n",
    "        \"doc_score_mean_top3\": float,\n",
    "        \"doc_label\": \"IT\" | \"NON_IT\",\n",
    "        \"thresholds\": {\"chunk\": tau_chunk, \"doc\": tau_doc}\n",
    "      }\n",
    "    \"\"\"\n",
    "    centroid = build_it_centroid(it_queries)     # (1, d)\n",
    "    C = embedder.embed_documents(chunks)         # (n, d)\n",
    "    sims = cosine_similarity(np.array(C), centroid).ravel()  # (n,)\n",
    "\n",
    "    results = []\n",
    "    for i, (chunk, sim) in enumerate(zip(chunks, sims)):\n",
    "        hit = bool(IT_REGEX.search(chunk))\n",
    "        final = sim + (regex_bonus if hit else 0.0)\n",
    "        results.append({\"idx\": i, \"sim\": float(sim), \"regex_hit\": hit, \"final\": float(final)})\n",
    "\n",
    "    # Aggregate to doc\n",
    "    finals = np.array([r[\"final\"] for r in results])\n",
    "    doc_max  = float(np.max(finals)) if len(finals) else 0.0\n",
    "    doc_top3 = float(np.mean(np.sort(finals)[-3:])) if len(finals) >= 3 else doc_max\n",
    "\n",
    "    # Decision rules (modify to taste):\n",
    "    #  - IT if either doc_top3 >= tau_doc OR (doc_max >= tau_doc and at least min_pos_chunks >= tau_chunk)\n",
    "    pos_chunks = int(np.sum(finals >= tau_chunk))\n",
    "    is_it = (doc_top3 >= tau_doc) or (doc_max >= tau_doc and pos_chunks >= min_pos_chunks_for_doc)\n",
    "\n",
    "    return {\n",
    "        \"chunk_scores\": results,\n",
    "        \"doc_score_max\": doc_max,\n",
    "        \"doc_score_mean_top3\": doc_top3,\n",
    "        \"doc_label\": \"IT\" if is_it else \"NON_IT\",\n",
    "        \"thresholds\": {\"chunk\": tau_chunk, \"doc\": tau_doc},\n",
    "        \"pos_chunks\": pos_chunks\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f90ad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IT_QUERIES = [\n",
    "    # General law references\n",
    "    \"Information Technology Act, 2000\",\n",
    "    \"IT Act 2000\",\n",
    "    \"Information Technology (Amendment) Act 2008\",\n",
    "    \"cyber law\",\n",
    "    \"electronic evidence\",\n",
    "    \"computer resource\",\n",
    "    \"digital signature\",\n",
    "    \"electronic record\",\n",
    "    \"intermediary liability\",\n",
    "    \"cyber crime\",\n",
    "    \"data privacy\",\n",
    "    \"hacking under IT Act\",\n",
    "    \"unauthorized access to computer system\",\n",
    "    \"cyber security offence\",\n",
    "\n",
    "    # Core sections with meaning\n",
    "    \"Section 43 - damage to computer or computer system\",\n",
    "    \"Section 65 - tampering with computer source documents\",\n",
    "    \"Section 66 - computer related offences\",\n",
    "    \"Section 66A - sending offensive messages through communication service\",\n",
    "    \"Section 66B - dishonestly receiving stolen computer resources\",\n",
    "    \"Section 66C - identity theft\",\n",
    "    \"Section 66D - cheating by personation using computer resources\",\n",
    "    \"Section 66E - violation of privacy\",\n",
    "    \"Section 67 - publishing or transmitting obscene material in electronic form\",\n",
    "    \"Section 67A - publishing sexually explicit material in electronic form\",\n",
    "    \"Section 67B - child pornography in electronic form\",\n",
    "    \"Section 68 - failure to comply with directions of Controller\",\n",
    "    \"Section 69 - interception, monitoring or decryption of information\",\n",
    "    \"Section 69A - blocking of public access to information\",\n",
    "    \"Section 70 - protected systems\",\n",
    "    \"Section 72 - breach of confidentiality and privacy\",\n",
    "    \"Section 72A - disclosure of information in breach of lawful contract\",\n",
    "    \"Section 73 - publishing false digital signature certificates\",\n",
    "    \"Section 74 - publication for fraudulent purpose\",\n",
    "\n",
    "    # Judicial / procedural parts\n",
    "    \"Adjudicating officer under IT Act\",\n",
    "    \"Cyber Appellate Tribunal\",\n",
    "    \"Jurisdiction under IT Act\",\n",
    "    \"Powers of Controller under IT Act\",\n",
    "    \"Appeal to Telecom Disputes Settlement and Appellate Tribunal\",\n",
    "    \"Electronic contracts under IT Act\",\n",
    "    \"Penalties and adjudication under IT Act\",\n",
    "    \"Liability of intermediaries under Section 79 of IT Act\",\n",
    "    \"Evidence Act and electronic records under Section 65B\",\n",
    "    \"Search and seizure of computer resources under IT Act\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "053454d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ PDF has 11 pages, processing first 11 pages\n"
     ]
    }
   ],
   "source": [
    "# pdf_path = \"data/University_Of_Delhi_vs_Shashi_Kiran_And_Ors_Etc_Etc_on_10_May_2022_1.PDF\"\n",
    "pdf_path = \"data/University_Of_Kerala_And_Ors_Etc_vs_Merlin_J_N_And_Anr_Etc_Etc_on_17_August_2022_1.pdf\"\n",
    "chunks = load_pdf_chunks(pdf_path, max_pages=MAX_PAGES_TO_PROCESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f0f1a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc label: NON_IT\n",
      "Doc max sim: 0.381 Top3 mean: 0.375 Pos chunks: 0\n",
      "[#59] final=0.381  sim=0.381  regex=False\n",
      "[#52] final=0.373  sim=0.373  regex=False\n",
      "[#51] final=0.371  sim=0.371  regex=False\n",
      "[#54] final=0.355  sim=0.355  regex=False\n",
      "[#57] final=0.353  sim=0.353  regex=False\n"
     ]
    }
   ],
   "source": [
    "# Suppose you already split a PDF into ~35 chunks (strings)\n",
    "pdf_chunks = chunks # list[str], your own chunker\n",
    "\n",
    "res = score_chunks_against_it(\n",
    "    chunks=pdf_chunks,\n",
    "    it_queries=IT_QUERIES,\n",
    "    tau_chunk=0.70,\n",
    "    tau_doc=0.70,\n",
    "    regex_bonus=0.20\n",
    ")\n",
    "\n",
    "print(\"Doc label:\", res[\"doc_label\"])\n",
    "print(\"Doc max sim:\", round(res[\"doc_score_max\"], 3),\n",
    "      \"Top3 mean:\", round(res[\"doc_score_mean_top3\"], 3),\n",
    "      \"Pos chunks:\", res[\"pos_chunks\"])\n",
    "\n",
    "# Inspect top contributing chunks\n",
    "top = sorted(res[\"chunk_scores\"], key=lambda r: r[\"final\"], reverse=True)[:5]\n",
    "for r in top:\n",
    "    print(f\"[#{r['idx']:02d}] final={r['final']:.3f}  sim={r['sim']:.3f}  regex={r['regex_hit']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f45bcd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"dataset/classification_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98efddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>doc_label</th>\n",
       "      <th>doc_max_sim</th>\n",
       "      <th>doc_top3_mean</th>\n",
       "      <th>positive_chunks</th>\n",
       "      <th>total_chunks</th>\n",
       "      <th>outcome_score</th>\n",
       "      <th>procedure_score</th>\n",
       "      <th>section_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ajay_Murlidhar_Batheja_vs_The_State_Of_Maharas...</td>\n",
       "      <td>IT</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.889</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arjun_Panditrao_Khotkar_vs_Kailash_Kushanrao_G...</td>\n",
       "      <td>IT</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.818</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Atul_Kumar_Singh_Atul_Rai_vs_State_Of_U_P_And_...</td>\n",
       "      <td>IT</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.825</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Awadhesh_Kumar_Paras_Nath_Pathak_vs_The_State_...</td>\n",
       "      <td>IT</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.877</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cyber_Crime_Police_Station_vs_Shivalinga_on_11...</td>\n",
       "      <td>IT</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.760</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            pdf_name doc_label  doc_max_sim  \\\n",
       "0  Ajay_Murlidhar_Batheja_vs_The_State_Of_Maharas...        IT        0.892   \n",
       "1  Arjun_Panditrao_Khotkar_vs_Kailash_Kushanrao_G...        IT        0.895   \n",
       "2  Atul_Kumar_Singh_Atul_Rai_vs_State_Of_U_P_And_...        IT        0.870   \n",
       "3  Awadhesh_Kumar_Paras_Nath_Pathak_vs_The_State_...        IT        0.909   \n",
       "4  Cyber_Crime_Police_Station_vs_Shivalinga_on_11...        IT        0.774   \n",
       "\n",
       "   doc_top3_mean  positive_chunks  total_chunks  outcome_score  \\\n",
       "0          0.889               14            40          0.516   \n",
       "1          0.818                3            40          0.457   \n",
       "2          0.825                4            11          0.514   \n",
       "3          0.877               10            40          0.422   \n",
       "4          0.760                5            21          0.579   \n",
       "\n",
       "   procedure_score  section_score  \n",
       "0            0.450          0.399  \n",
       "1            0.459          0.462  \n",
       "2            0.519          0.465  \n",
       "3            0.495          0.555  \n",
       "4            0.494          0.296  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['doc_label'] == 'IT']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
